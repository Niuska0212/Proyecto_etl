# -*- coding: utf-8 -*-
"""ETL_proyecto.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_3hZO4w_A2Urrqt040IpIz4reDbRUUwr
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from sklearn.preprocessing import LabelEncoder, MinMaxScaler    #para normalizar
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score
import joblib
import os

# ====================Parte de Arath ====================
# ==================== FUNCIONES DE CARGA ====================
#Para cargar desde un CSV
def load_csv(file_path):
    try:
        df = pd.read_csv(file_path)
        print("Datos cargados exitosamente desde CSV.")
        return df
    except FileNotFoundError:
        print(f"Error: Archivo CSV no encontrado en {file_path}")
        return None
    except Exception as e:
        print(f"Error inesperado al cargar CSV: {e}")
        return None

#Para cargar desde un Excel
def load_excel(file_path):
    try:
        df = pd.read_excel(file_path)
        print("Datos cargados exitosamente desde Excel.")
        return df
    except FileNotFoundError:
        print(f"Error: Archivo Excel no encontrado en {file_path}")
        return None
    except Exception as e:
        print(f"Error inesperado al cargar Excel: {e}")
        return None
#Para cargar desde un Json
def load_json(file_path):
    try:
        #agrege lines=true para que sepa leer archivos JSON lines
        df = pd.read_json(file_path,lines=True)
        print("Datos cargados exitosamente desde JSON.")
        return df
    except FileNotFoundError:
        print(f"Error: Archivo JSON no encontrado en {file_path}")
        return None
    except Exception as e:
        print(f"Error inesperado al cargar JSON: {e}")
        return None

# ==================== FUNCIONES DE LIMPIEZA ====================
def clean_data(df):
    try:
        print("Iniciando limpieza de datos...")
        
        #Condicional para verificar si el DataFrame es vacío o None
        if df is None or df.empty:
            print("Error: DataFrame vacío o None recibido")
            return None

        # Primero hay que manejar los valores nulos para rellenarlos con algo distinto
        #df['children'].fillna(0, inplace=True)  # Nulos en la columna 'children' se rellenan con un 0
        df = df.assign(children=df['children'].fillna(0)) # Nulos en la columna 'children' se rellenan con un 0
        df['country'].fillna('Unknown', inplace=True)  # Nulos en la columna 'coutry' se rellenan con 'Unknow'

        # Esta parte es para las fechas jeje, todas las fechas se poner en un solo formato estandar
        if 'reservation_status_date' in df.columns:
            df['reservation_status_date'] = pd.to_datetime(df['reservation_status_date'], errors='coerce')

        # Esto es para eliminar columnas que no nos sirvan para el analisis jeje, igual luego checamos que otras,
        # de mientras solo elimino agent y company
        columns_to_drop = ['agent', 'company']
        df.drop(columns=[col for col in columns_to_drop if col in df.columns], inplace=True)

        # Se valida que esas columnas tengan valores validos, sino se llena con la mediana o promedio de esa columna
        numeric_columns = ['adr', 'lead_time', 'stays_in_week_nights', 'stays_in_weekend_nights']
        for col in numeric_columns:
            if col in df.columns:
                df[col].fillna(df[col].median(), inplace=True) # Aqui se rellena con la mediana jeje

        print("Limpieza de datos completada.")
        return df
    except Exception as e:
        print(f"Error durante la limpieza de datos: {e}")
        return None

# ================= Parte de Jesus =================
# ==================== FUNCIONES DE TRANSFORMACIÓN ====================
def one_hot_encoding(df, column_name):
    """
    Aplica codificación one-hot a una columna del DataFrame.
    """
    try:
        if column_name not in df.columns:
            print(f"Advertencia: Columna {column_name} no existe para one-hot encoding")
            return df
            
        df_encoded = pd.get_dummies(df, columns=[column_name], prefix=[column_name])
        print(f"Codificación one-hot aplicada a {column_name}.")
        return df_encoded
    except Exception as e:
        print(f"Error en one-hot encoding: {e}")
        return df

def label_encoding(df, column_name):
    """
    Aplica codificación de etiquetas a una columna del DataFrame.
    """
    try:
        if column_name not in df.columns:
            print(f"Advertencia: Columna {column_name} no existe para label encoding")
            return df
            
        le = LabelEncoder()
        df[column_name] = le.fit_transform(df[column_name])
        print(f"Codificación de etiquetas aplicada a {column_name}.")
        return df
    except Exception as e:
        print(f"Error en label encoding: {e}")
        return df

def min_max_normalization(df, column_names):
    """
    Aplica normalización Min-Max a las columnas especificadas.
    """
    try:
        missing_cols = [col for col in column_names if col not in df.columns]
        if missing_cols:
            print(f"Advertencia: Columnas {missing_cols} no existen para normalización")
            column_names = [col for col in column_names if col in df.columns]
            if not column_names:
                return df
                
        scaler = MinMaxScaler()
        df[column_names] = scaler.fit_transform(df[column_names])
        print(f"Normalización Min-Max aplicada a {column_names}.")
        return df
    except Exception as e:
        print(f"Error en normalización: {e}")
        return df

def create_new_columns(df):
    """
    Crea nuevas columnas en el DataFrame.
    """
    try:
        required_cols = ['stays_in_weekend_nights', 'stays_in_week_nights', 'is_canceled', 'country']
        missing_cols = [col for col in required_cols if col not in df.columns]
        if missing_cols:
            print(f"Advertencia: No se pueden crear columnas nuevas. Faltan: {missing_cols}")
            return df
            
        df = df.assign(
            is_weekend=df['stays_in_weekend_nights'] > 0,
            total_stay=df['stays_in_week_nights'] + df['stays_in_weekend_nights'],
            is_canceled=df['is_canceled'].apply(lambda x: 1 if x == 1 else 0),
            region=df['country'].apply(lambda x: 'Europe' if x in ['PRT', 'ESP', 'FRA'] else 'Other')
        )
        print("Nuevas columnas creadas exitosamente.")
        return df
    except Exception as e:
        print(f"Error creando nuevas columnas: {e}")
        return df

def calculate_average_adr(df):
    """
    Calcula el promedio de ADR por tipo de hotel.
    """
    try:
        hotel_columns = [col for col in df.columns if col.startswith('hotel_')]
        if not hotel_columns:
            print("Advertencia: No hay columnas de hotel para calcular ADR")
            return None
            
        average_adr = df.groupby(hotel_columns)['adr'].mean().reset_index()
        print("Promedio de ADR por hotel calculado.")
        return average_adr
    except Exception as e:
        print(f"Error calculando ADR promedio: {e}")
        return None

def transform_data(df):
    """
    Realiza la transformación completa de los datos.
    """
    try:
        print("Iniciando transformación de datos...")
        df = one_hot_encoding(df, 'hotel')
        df = label_encoding(df, 'meal')
        numeric_columns = ['adr', 'lead_time', 'stays_in_week_nights', 'stays_in_weekend_nights']
        df = min_max_normalization(df, numeric_columns)
        df = create_new_columns(df)
        print("Transformación de datos completada.")
        return df
    except Exception as e:
        print(f"Error en transformación general: {e}")
        return df


# ====================Parte de YAYA ====================
# ==================== ANÁLISIS EXPLORATORIO ====================
def exploratory_analysis(df_cleaned):
    try:
        print("\nIniciando análisis exploratorio...")
        
        # Matriz de correlación
        #conteo de valores
        if df_cleaned is not None:
            numeric_df = df_cleaned.select_dtypes(include=['int64', 'float64'])
            if not numeric_df.empty:
                correlation_matrix = numeric_df.corr()
                print("\nMatriz de correlación:")
                print(correlation_matrix)

                # Mapa de calor
                plt.figure(figsize=(12, 8))
                sns.heatmap(correlation_matrix, annot=True, fmt=".2f", cmap='coolwarm', vmin=-1, vmax=1)
                plt.title("Matriz de Correlación", fontsize=16)
                plt.savefig("Matriz de Correlación.png") #Guardar la imagen
                plt.show()
            else:
                print("Advertencia: No hay columnas numéricas para matriz de correlación")

        # Conteo de hoteles
        #Grafica la columna 'hotel' que contamos anteriormente
        if 'hotel' in df_cleaned.columns:
            hotel_counts = df_cleaned['hotel'].value_counts()
            print("\nDistribución de hoteles:")
            print(hotel_counts)

            # Gráfica de hoteles
            df_cleaned['hotel'].value_counts().plot(kind='bar', title='Distribución de hoteles')
            plt.xlabel('Tipo de hotel')
            plt.ylabel('Frecuencia')
            plt.savefig("Distribución de hoteles.png") #Guardar la imagen
            plt.show()

        # Gráfica ADR
        if 'adr' in df_cleaned.columns:
            df_cleaned['adr'].plot(kind='hist', title='Distribución de ADR', bins=30)
            plt.xlabel('ADR')
            plt.ylabel('Frecuencia')
            plt.savefig("Distribución de ADR.png") #Guardar la imagen
            plt.show()

        # Análisis por país
        # Verifica si la columna 'country' existe
        if 'country' in df_cleaned.columns:
            #conteo
            country_counts = df_cleaned['country'].value_counts()

            # Gráfica de países
            top_countries = country_counts.head(15)
            top_countries.plot(kind='bar', title='Top 15 países de origen de los clientes', color='skyblue')
            plt.xlabel('País')
            plt.ylabel('Número de clientes')
            plt.xticks(rotation=45) #rotacion del nombre eje X
            plt.savefig("Top 15 países de origen de los clientes.png") #Guardar la imagen
            plt.show()

        # Análisis de cancelaciones
        #CAJAS Y BIGOTES permite analizar si existe una relación entre el tiempo de anticipación y la probabilidad de que una reserva sea cancelada.
        if 'lead_time' in df_cleaned.columns and 'is_canceled' in df_cleaned.columns:
            plt.figure(figsize=(10, 6))
            sns.boxplot(x='is_canceled', y='lead_time', data=df_cleaned, hue='is_canceled', palette='pastel', legend=False)
            plt.title('Lead Time vs Cancelaciones', fontsize=16)
            plt.xlabel('Cancelada (0: No, 1: Si)', fontsize=12)
            plt.ylabel('Lead Time (días)', fontsize=12)
            plt.savefig("Lead Time vs Cancelaciones.png") #Guardar la imagen
            plt.show()

        print("Análisis exploratorio completado.")
    except Exception as e:
        print(f"Error durante análisis exploratorio: {e}")


# ==================== Parte de Niuska ====================
# ==================== FUNCION MODELO PREDICTIVO ====================
#modelo predictivo usando Random Forest.
def load_and_prepare_data(file_path):
    
    #Carga y prepara los datos normalizados para el modelo predictivo.
    try:
        print("\nCargando y preparando datos...")

        # Cargar datos desde el archivo especificado
        if file_path.endswith(".csv"):
            df = pd.read_csv(file_path)
        elif file_path.endswith(".xlsx"):
            df = pd.read_excel(file_path)
        elif file_path.endswith(".json"):
            df = pd.read_json(file_path)
        else:
            print("Formato de archivo no soportado.")
            return None, None, None, None

        print(f"Datos cargados. Filas: {len(df)}")

        # Eliminar columnas problemáticas
        cols_to_drop = ['reservation_status', 'reservation_status_date']
        df = df.drop(columns=[col for col in cols_to_drop if col in df.columns])

        # Convertir booleanos y categóricas
        bool_cols = df.select_dtypes(include=['bool']).columns
        for col in bool_cols:
            df[col] = df[col].astype(int)

        categorical_cols = df.select_dtypes(include=['object']).columns
        df = pd.get_dummies(df, columns=categorical_cols, drop_first=True)

        # Dividir datos
        X = df.drop(columns=['is_canceled'])
        y = df['is_canceled']


        X_train, X_test, y_train, y_test = train_test_split( 
            X, y, 
            test_size=0.3,  # 70% entrenamiento, 30% prueba
            random_state=42, #semilla
            stratify=y #estratificar
        )

        print("Preparación de datos completada")
        return X_train, X_test, y_train, y_test

    except Exception as e:
        print(f"Error en la preparación de datos: {e}")
        return None, None, None, None

def train_random_forest(X_train, y_train):
    #Entrena un modelo Random Forest con los datos preparados
    try:

        print("\nEntrenando modelo Random Forest...")
        rf_model = RandomForestClassifier(
            n_estimators=150,
            max_depth=12,
            min_samples_split=5,
            class_weight='balanced',
            random_state=42,
            n_jobs=-1
        )
        
        rf_model.fit(X_train, y_train)
        print("Entrenamiento completado")
        return rf_model
        
    except Exception as e:
        print(f"Error en entrenamiento del modelo: {e}")
        return None

def evaluate_and_save_model(model, X_test, y_test):
    #Evalúa y guarda el modelo entrenado"""
    try:
        
        print("\nEvaluando modelo...")
        y_pred = model.predict(X_test)
        y_proba = model.predict_proba(X_test)[:, 1]

        print("\nPrecisión del modelo:", accuracy_score(y_test, y_pred))
        #print("\nReporte de clasificación:", classification_report(y_test, y_pred)) 
        
        # Métricas
        metrics = {
            'Exactitud': accuracy_score(y_test, y_pred),
            'Precisión': precision_score(y_test, y_pred),
            'Sensibilidad': recall_score(y_test, y_pred),
            'F1-Score': f1_score(y_test, y_pred),
            'ROC-AUC': roc_auc_score(y_test, y_proba)
        }
        
        print("\nMétricas del modelo:")
        for name, value in metrics.items():
            print(f"{name}: {value:.2f}")
        
        print("\nMatriz de confusión:")
        print(confusion_matrix(y_test, y_pred))
        print("[[TN FP]\n [FN TP]]") #True Negative, False Positive, False Negative, True Positive
        
        # Guardar resultados
        results = pd.DataFrame({
            'Actual': y_test.values,
            'Predicho': y_pred,
            'Probabilidad_Cancelacion': y_proba
        })
        
        #results.to_csv("random_forest_results.csv", index=False)
        #joblib.dump(model, 'random_forest_model.pkl')
        
        #print("\nResultados guardados en 'random_forest_results.csv'")
        print("Modelo guardado en 'random_forest_model.pkl'")
        
        return results #Retorna el DataFrame en lugar de metirlo en un archivo
        
    except Exception as e:
        print(f"Error en evaluación del modelo: {e}")
        return None

# ==================== FUNCION PARA GUARDAR DATOS ====================
def save_csv(data,file_path):
    try:
        data.to_csv(file_path, index=False)
        print(f"Datos guardados en {file_path}")
    except Exception as e:
        print(f"Error al guardar datos: {e}")

def save_excel(data,file_path):
    try:
        data.to_excel(file_path, index=False)
        print(f"Datos guardados en {file_path}")
    except Exception as e:
        print(f"Error al guardar datos: {e}")

def save_json(data,file_path):
    try:
        data.to_json(file_path)
        print(f"Datos guardados en {file_path}")
    except Exception as e:
        print(f"Error al guardar datos: {e}")





# ==================== FUNCIÓN PRINCIPAL ====================
def main():
    # Cargar datos
    print("\n" + "="*50)
    print("ETL HOTEL BOOKINGS - CARGA DE DATOS")
    print("="*50)

    while True:  # Bucle para reintentar la selección de archivo
        print("Seleccione el tipo de archivo para cargar los datos:")
        print("1. CSV")
        print("2. Excel")
        print("3. JSON")

        try:
            option = int(input("Ingrese el número de la opción deseada: "))

            # Construir la ruta del archivo según la opción seleccionada
            base_file_name = "hotel_bookings"
            if option == 1:
                file_path = f"{base_file_name}.csv"
                df = load_csv(file_path)
            elif option == 2:
                file_path = f"{base_file_name}.xlsx"
                df = load_excel(file_path)
            elif option == 3:
                file_path = f"{base_file_name}.json"
                df = load_json(file_path)
            else:
                print("Opción no válida. Por favor, seleccione una opción válida.")
                continue
            
            # Verificar si el archivo se cargó correctamente
            if df is not None:
                print(f"Archivo cargado exitosamente desde {file_path}.")
                break  # Salir del bucle si todo salió bien
            else:
                print("No se pudo cargar el archivo. Intente nuevamente.")
        
        except ValueError:
            print("Entrada no válida. Por favor, ingrese un número.")
        except Exception as e:
            print(f"Error inesperado: {e}")

    # Limpieza de datos
    print("\n" + "="*50)
    print("ETL HOTEL BOOKINGS - LIMPIEZA DE DATOS")
    print("="*50)
    df_cleaned = clean_data(df)

    while True:  # Bucle para reintentar la selección del formato de guardado
        try:
            # Transformación de datos
            print("\n" + "="*50)
            print("ETL HOTEL BOOKINGS - TRANSFORMACIÓN DE DATOS")
            print("="*50)
            df_transformed = transform_data(df_cleaned)

            print("\nSeleccione el formato para guardar los datos normalizados:")
            print("1. CSV")
            print("2. Excel")
            print("3. JSON")
            save_option = int(input("Ingrese el número de la opción deseada: "))
            
            result_file_name = "hotel_bookings_normalized"
            if save_option == 1:
                save_csv(df_transformed, f"{result_file_name}.csv")
            elif save_option == 2:
                save_excel(df_transformed, f"{result_file_name}.xlsx")
            elif save_option == 3:
                save_json(df_transformed, f"{result_file_name}.json")
            else:
                print("Opción no válida. Intente nuevamente.")
                continue  # Reinicia el bucle si la opción no es válida
            
            print("Datos guardados exitosamente.")
            break  # Salir del bucle después de guardar los datos
        
        except ValueError:
            print("Entrada no válida. Por favor, ingrese un número.")
        except Exception as e:
            print(f"\nError al guardar datos: {e}")

    # Análisis exploratorio
    print("\n" + "="*50)
    print("ETL HOTEL BOOKINGS - ANÁLISIS EXPLORATORIO")
    print("="*50)
    exploratory_analysis(df_cleaned)

    # Modelo predictivo
    print("\n" + "="*50)
    print("MODELO PREDICTIVO - RANDOM FOREST")
    print("="*50)

    while True:  # Bucle para reintentar la selección de archivo para los datos normalizados
        print("Seleccione el tipo de archivo para cargar los datos normalizados:")
        print("1. CSV")
        print("2. Excel")
        print("3. JSON")

        try:
            option = int(input("Ingrese el número de la opción deseada: "))
            base_file_name = "hotel_bookings_normalized"

            if option == 1:
                file_path = f"{base_file_name}.csv"
            elif option == 2:
                file_path = f"{base_file_name}.xlsx"
            elif option == 3:
                file_path = f"{base_file_name}.json"
            else:
                print("Opción no válida. Intente nuevamente.")
                continue  # Reinicia el bucle

            # Verificar si el archivo existe y proceder con su carga y preparación
            if os.path.exists(file_path):
                print(f"Archivo seleccionado: {file_path}")
                X_train, X_test, y_train, y_test = load_and_prepare_data(file_path)
                if X_train is not None:
                    print("Datos cargados y preparados exitosamente.")
                    break  # Salir del bucle si todo salió bien
                else:
                    print("Error en la preparación de los datos. Intente nuevamente.")
            else:
                print(f"No se encontró el archivo {file_path}. Intente nuevamente.")
        
        except ValueError:
            print("Entrada no válida. Por favor, ingrese un número.")
        except Exception as e:
            print(f"Error inesperado: {e}")

    # Entrenar y evaluar modelo
    if X_train is not None:
        rf_model = train_random_forest(X_train, y_train)
        
        if rf_model is not None:
            model_results = evaluate_and_save_model(rf_model, X_test, y_test)
            
            while True:  # Bucle para reintentar la selección del formato de guardado
                try:
                    print("\nSeleccione el formato para guardar los resultados del modelo:")
                    print("1. CSV")
                    print("2. Excel")
                    print("3. JSON")
                    save_option = int(input("Ingrese el número de la opción deseada: "))

                    result_file_name = "random_forest_results"
                    if save_option == 1:
                        save_csv(model_results, f"{result_file_name}.csv")
                    elif save_option == 2:
                        save_excel(model_results, f"{result_file_name}.xlsx")
                    elif save_option == 3:
                        save_json(model_results, f"{result_file_name}.json")
                    else:
                        print("Opción no válida. Intente nuevamente.")
                        continue  # Reinicia el bucle si la opción no es válida
                    
                    print("Resultados guardados exitosamente.")
                    break  # Salir del bucle tras guardar los resultados
                
                except ValueError:
                    print("Entrada no válida. Por favor, ingrese un número.")
                except Exception as e:
                    print(f"\nError al guardar resultados: {e}")

    print("\nProceso completado.")

if __name__ == "__main__":
    main()

# ==================== FIN DEL SCRIPT ====================
